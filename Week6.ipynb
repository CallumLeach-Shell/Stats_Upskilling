{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Basic MCMC\n",
    "---\n",
    "\n",
    "### Exercise 1: Questions about last week's work:\n",
    "1. Why are conjugate priors useful?\n",
    "2. How do we solve the cases where we do not have closed form? \n",
    "3. If we take the regression example from the previous week 4 how can we estimate the parameters?\n",
    "4. How can we determine the priors?\n",
    "5. Why might the distribution of the priors be different?\n",
    "6. Using a Normal prior for Beta and an inverse Gamma prior for sigma^2 can you derive the posterior distribution?\n",
    "7. How does this case link to Ridge Regression?\n",
    "\n",
    "### Exercise 2: MCMC Basics:\n",
    "1. What is Markov chain Monte Carlo (MCMC)?\n",
    "2. When can we sample directly from the posterior?\n",
    "3. What other techniques could we use if we cannot directly sample?\n",
    "4. What pieces of information might we need to decide when running an MCMC?\n",
    "5. What challenges might we have in running an MCMC?\n",
    "6. What is the difference between the following sampling algorithms?\n",
    "    - Gibbs Sampling.\n",
    "    - Random Walk Metropolis Hastings Algorithm.\n",
    "    - Adaptive MCMC.\n",
    "    - Metropolis Adjusted Langevin Algorithm (Mala).\n",
    "    - Riemann Manifold Metropolis Adjusted Langevin Algorithm (mMala)\n",
    "7. When might we want to use the different cases?\n",
    "\n",
    "### Exercise 3: Coding MCMC:\n",
    "\n",
    "- Code up a Gibbs Sampling Algorithm.\n",
    "- Code up a Random Walk Metropolis Hastings Algorithm.\n",
    "- For a comparable case do they give the same answers?\n",
    "- How and why do we use Bayesian Inference?\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
